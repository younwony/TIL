# 메모리 관리 (Memory Management)

> 운영체제가 메인 메모리를 효율적으로 관리하고, 프로세스에게 메모리 공간을 할당/회수하는 기법

## 핵심 개념

- **가상 메모리**: 물리 메모리보다 큰 주소 공간을 프로세스에게 제공하는 기법
- **페이징**: 메모리를 고정 크기 블록(페이지)으로 분할하여 관리
- **세그멘테이션**: 논리적 단위(코드, 데이터, 스택)로 메모리를 분할
- **페이지 교체**: 메모리가 부족할 때 어떤 페이지를 swap out할지 결정하는 알고리즘
- **메모리 단편화**: 메모리 공간이 비효율적으로 분산되는 현상

## 쉽게 이해하기

**메모리 관리**를 도서관 시스템에 비유할 수 있습니다.

### 가상 메모리 = 도서관 대출 시스템

도서관에 있는 모든 책을 집에 가져올 수는 없습니다. 하지만 도서관 카드만 있으면 마치 모든 책이 내 것인 것처럼 필요할 때마다 빌려볼 수 있죠.

컴퓨터도 마찬가지입니다. 8GB RAM을 가진 컴퓨터에서 16GB짜리 프로그램을 실행할 수 있는 이유는, 당장 필요한 부분만 메모리에 올리고 나머지는 하드디스크(창고)에 보관하기 때문입니다.

**왜 이렇게 하나요?**
- 물리 메모리는 비싸고 용량이 제한적
- 프로그램 전체가 항상 필요한 게 아님 (90%는 사용 안 하는 코드일 수도)
- 여러 프로그램을 동시에 실행해야 함

### 페이징 = 책을 챕터별로 대출

100페이지짜리 책을 읽을 때, 1장을 읽는 동안 나머지 9개 장은 굳이 들고 있을 필요가 없습니다.

- **페이지**: 책의 각 챕터 (일정한 크기로 나눈 조각)
- **프레임**: 내 책상 위 공간 (책을 놓을 수 있는 자리)
- **페이지 폴트**: "2장 읽고 싶은데 책상에 없네? 창고에서 가져와야지" (디스크에서 로드)

### 페이지 교체 = 책상 정리

책상 위 공간(메모리)이 꽉 찼는데 새 책(페이지)을 올려야 한다면?

| 전략 | 비유 | 왜 이 방법인가? |
|------|------|----------------|
| FIFO | "가장 오래 전에 올려놓은 책 치우기" | 구현 간단, 공정함 |
| LRU | "가장 오랫동안 안 읽은 책 치우기" | 최근에 쓴 건 또 쓸 확률 높음 |
| LFU | "총 읽은 횟수가 가장 적은 책 치우기" | 자주 쓰는 건 중요한 거니까 |

### 스레싱 = 계속 창고 왔다갔다

책상이 너무 작아서 책을 펼치자마자 다른 책이 필요해지고, 그걸 가져오면 또 다른 책이 필요한 상황. 결국 공부는 못 하고 창고 왔다갔다만 하는 것이 **스레싱**입니다.

**왜 발생하나요?**
- 실행 중인 프로세스가 너무 많음
- 각 프로세스에 할당된 메모리가 너무 적음
- 결과: CPU는 100%인데 실제 작업은 0%

---

## 상세 설명

### 물리 메모리 vs 가상 메모리

| 구분 | 물리 메모리 | 가상 메모리 |
|------|------------|------------|
| 정의 | 실제 RAM 하드웨어 | OS가 제공하는 추상화된 메모리 공간 |
| 크기 | 하드웨어 제한 | 이론적으로 무제한 (디스크 활용) |
| 주소 | 물리 주소 | 논리 주소 (가상 주소) |
| 접근 | 직접 접근 | MMU를 통한 주소 변환 필요 |

**왜 가상 메모리를 사용하는가?**

1. **메모리 추상화**: 각 프로세스가 전체 메모리를 독점하는 것처럼 프로그래밍 가능
2. **메모리 보호**: 프로세스 A가 프로세스 B의 메모리에 접근 불가
3. **메모리 확장**: 물리 메모리보다 큰 프로그램 실행 가능
4. **메모리 공유**: 공유 라이브러리를 여러 프로세스가 공유

**만약 가상 메모리가 없다면?**
- 각 프로세스가 물리 주소를 직접 사용 → 주소 충돌
- 악성 프로그램이 다른 프로세스 메모리 접근 가능
- 물리 메모리 크기 이상의 프로그램 실행 불가

---

### 페이징 (Paging)

메모리를 **고정 크기의 블록**으로 나누어 관리하는 기법

- **페이지 (Page)**: 가상 메모리의 고정 크기 블록 (보통 4KB)
- **프레임 (Frame)**: 물리 메모리의 고정 크기 블록
- **페이지 테이블**: 가상 주소 → 물리 주소 매핑 정보 저장

```
가상 주소 구조 (32비트 기준):
+----------------+------------------+
|   페이지 번호   |   페이지 오프셋   |
|    (20비트)    |     (12비트)     |
+----------------+------------------+
```

**왜 고정 크기인가?**
- 할당/해제가 단순 (빈 프레임 찾아서 넣기만 하면 됨)
- 외부 단편화 없음 (모든 조각이 같은 크기)
- 메모리 관리 테이블 크기 예측 가능

**권장 (O): 페이징 사용**

```
장점:
- 외부 단편화 없음
- 메모리 할당/해제가 간단
- 비연속 메모리 할당 가능

단점:
- 내부 단편화 발생 가능 (마지막 페이지)
- 페이지 테이블 오버헤드
```

---

### 세그멘테이션 (Segmentation)

메모리를 **논리적 단위**로 나누어 관리하는 기법

| 세그먼트 | 설명 | 특징 |
|---------|------|------|
| Code | 실행 코드 영역 | 읽기 전용, 공유 가능 |
| Data | 전역 변수, 정적 변수 | 읽기/쓰기 |
| Heap | 동적 메모리 할당 영역 | 위로 증가 |
| Stack | 함수 호출, 지역 변수 | 아래로 증가 |

**왜 논리적 단위인가?**
- 프로그래머 관점에서 자연스러움 (코드, 데이터, 스택 분리)
- 세그먼트별 접근 권한 설정 가능 (Code는 읽기 전용)
- 세그먼트 단위 공유 가능 (공유 라이브러리)

**비권장 (X): 세그멘테이션만 사용**

```
문제점:
- 외부 단편화 발생 (가변 크기)
- 메모리 컴팩션 필요 (비용 높음)
- 관리 복잡성 증가
```

**만약 지키지 않으면?**
- 총 여유 공간은 충분한데 연속 공간 부족으로 할당 실패
- 주기적인 메모리 재배치로 시스템 일시 정지

---

### 페이지드 세그멘테이션 (Paged Segmentation)

세그멘테이션과 페이징을 결합한 방식

```
[가상 주소]
+------------+-----------+------------+
| 세그먼트 번호 | 페이지 번호 | 오프셋     |
+------------+-----------+------------+
      ↓
[세그먼트 테이블] → [페이지 테이블] → [물리 주소]
```

**왜 결합하는가?**
- 세그멘테이션의 장점: 논리적 구조, 접근 권한 관리
- 페이징의 장점: 외부 단편화 없음, 관리 단순
- 결합: 둘의 장점을 모두 취함

---

### 메모리 단편화 (Fragmentation)

#### 내부 단편화 (Internal Fragmentation)

할당된 메모리 블록 내부의 낭비 공간

```
[4KB 페이지]
+------------------+--------+
|   실제 사용 3KB  |  낭비  |
+------------------+--------+
                    1KB 낭비 (내부 단편화)
```

**왜 발생하는가?**
- 고정 크기 할당 시 요청 크기가 정확히 맞지 않음
- 예: 3KB 필요한데 4KB 페이지 할당

**해결책:**
- 작은 페이지 크기 사용 (오버헤드 증가)
- Slab Allocator (커널에서 사용)

#### 외부 단편화 (External Fragmentation)

할당/해제 반복으로 메모리가 조각화

```
[메모리 상태]
+-----+------+-----+------+-----+
| 사용 | 빈칸 | 사용 | 빈칸 | 사용 |
| 2KB | 1KB | 3KB | 2KB | 1KB |
+-----+------+-----+------+-----+

총 빈 공간: 3KB
하지만 3KB 연속 할당 불가!
```

**왜 발생하는가?**
- 가변 크기 할당 시 작은 빈 공간들이 흩어짐
- 연속 공간이 필요한 요청 처리 불가

**해결책:**
- 페이징 사용 (고정 크기로 조각화 방지)
- 메모리 컴팩션 (비용 높음)
- Buddy System (2의 거듭제곱 크기로 분할)

---

## 동작 원리

### 주소 변환 과정 (Paging)

```
┌─────────────────────────────────────────────────────────────┐
│                        CPU                                  │
│   가상 주소: [페이지 번호 | 오프셋]                            │
└─────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌─────────────────────────────────────────────────────────────┐
│                        TLB                                  │
│              (Translation Lookaside Buffer)                 │
│                    캐시 히트? ─────────────────────┐         │
└─────────────────────────────────────────────────────────────┘
         │ Miss                                     │ Hit
         ▼                                          │
┌─────────────────────────────────────────────────────────────┐
│                   페이지 테이블                              │
│   페이지 번호 → 프레임 번호 조회                              │
│   (Page Table Base Register 사용)                           │
└─────────────────────────────────────────────────────────────┘
         │                                          │
         ▼                                          ▼
┌─────────────────────────────────────────────────────────────┐
│                      물리 주소                              │
│            [프레임 번호 | 오프셋] → 실제 메모리 접근          │
└─────────────────────────────────────────────────────────────┘
```

**왜 TLB가 필요한가?**
- 페이지 테이블이 메모리에 있음 → 매 접근마다 메모리 2번 접근 (테이블 + 실제 데이터)
- TLB는 최근 변환 정보를 CPU 캐시에 저장 → 1번 접근으로 단축
- TLB 히트율 99%+ → 성능 핵심

**만약 TLB가 없다면?**
- 모든 메모리 접근이 2배 느려짐
- 현대 시스템에서는 사용 불가능한 수준의 성능 저하

---

### 페이지 폴트 처리 과정

```
1. CPU가 가상 주소 접근
2. 페이지 테이블에서 해당 페이지의 valid bit 확인
3. valid bit = 0 (페이지 폴트 발생!)
4. OS 인터럽트 핸들러 호출
5. 디스크에서 해당 페이지 찾기
6. 빈 프레임에 페이지 적재 (없으면 페이지 교체)
7. 페이지 테이블 갱신
8. 중단된 명령어 재실행
```

**왜 페이지 폴트가 느린가?**
- 메모리 접근: ~100ns
- 디스크 접근: ~10ms (SSD), ~100ms (HDD)
- 약 **10만~100만 배** 느림

**만약 페이지 폴트가 빈번하면?**
- 디스크 I/O 대기로 CPU 놀게 됨
- 시스템 전체 응답 속도 저하
- 극단적 경우 → 스레싱

---

### 페이지 교체 알고리즘

| 알고리즘 | 설명 | 왜 이 방법인가? | 단점 |
|---------|------|----------------|------|
| **FIFO** | 가장 먼저 들어온 페이지 교체 | 구현 간단, 공정 | Belady's Anomaly |
| **LRU** | 가장 오래 사용되지 않은 페이지 교체 | 지역성 원리 활용 | 구현 복잡 |
| **LFU** | 가장 적게 사용된 페이지 교체 | 사용 빈도 고려 | 최근 적재된 페이지에 불리 |
| **Optimal** | 가장 오랫동안 사용되지 않을 페이지 교체 | 이론적 최적 | 미래 예측 불가 |
| **Clock** | FIFO + 참조 비트 활용 | LRU 근사, 효율적 | LRU보다 부정확 |

**왜 LRU가 많이 사용되는가?**
- **지역성 원리(Locality of Reference)**: 최근 사용된 것은 또 사용될 확률 높음
- Optimal에 가장 가까운 실용적 알고리즘
- 시간 지역성: 최근 참조된 데이터 다시 참조
- 공간 지역성: 인접 데이터 함께 참조

**LRU 구현 방식**

```java
// LinkedHashMap을 활용한 LRU 캐시
public class LRUCache<K, V> extends LinkedHashMap<K, V> {
    private final int capacity;

    public LRUCache(int capacity) {
        // accessOrder=true: 접근 순서 기반 정렬
        super(capacity, 0.75f, true);
        this.capacity = capacity;
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        return size() > capacity;  // 용량 초과 시 가장 오래된 항목 제거
    }
}
```

**왜 LinkedHashMap인가?**
- 삽입/접근 순서 유지
- O(1) 접근/삽입/삭제
- `removeEldestEntry()`로 LRU 정책 구현 용이

---

### 스레싱 (Thrashing)

**정의**: 페이지 폴트가 과도하게 발생하여 CPU가 실제 작업보다 페이지 교체에 더 많은 시간을 소비하는 현상

```
CPU 사용률
    │
    │     ╱╲
    │    ╱  ╲
    │   ╱    ╲_____ 스레싱 발생
    │  ╱
    │ ╱
    └──────────────────→ 다중 프로그래밍 정도
```

**왜 발생하는가?**
- 프로세스에 할당된 프레임 수 < 필요한 최소 프레임 수
- 너무 많은 프로세스가 메모리를 나눠 씀
- Working Set보다 적은 메모리 할당

**해결책:**

| 방법 | 설명 | 왜 효과적인가? |
|------|------|---------------|
| Working Set 모델 | 프로세스가 필요한 최소 프레임 수 보장 | 지역성 기반 필수 페이지 유지 |
| PFF (Page Fault Frequency) | 페이지 폴트 빈도 기반 프레임 조절 | 동적으로 최적 프레임 수 유지 |
| 프로세스 중단 | 일부 프로세스 swap out | 남은 프로세스에 충분한 메모리 제공 |

**만약 해결하지 않으면?**
- 시스템 응답 속도 급격히 저하
- CPU 사용률 100%인데 실제 작업량 0%
- 사용자 체감: "컴퓨터가 멈춤"

---

## 예제 코드

### 메모리 영역 확인 (Linux)

```bash
# 프로세스의 메모리 맵 확인
cat /proc/[PID]/maps

# 출력 예시
# 주소범위             권한  오프셋  장치  inode  경로
# 00400000-00452000   r-xp  00000000 08:01 123456 /bin/bash  (Code)
# 00651000-00652000   r--p  00051000 08:01 123456 /bin/bash  (Data)
# 00652000-0065b000   rw-p  00052000 08:01 123456 /bin/bash  (Data)
# 7f8a1c000000-7f8a1c021000 rw-p (Heap)
# 7ffee8dfb000-7ffee8e1c000 rw-p [stack]
```

### Java 메모리 영역

```java
public class MemoryExample {
    // Method Area (메서드 영역) - 클래스 정보, static 변수
    private static final int CONSTANT = 100;
    private static int staticVar = 10;

    // Heap (힙) - 객체, 인스턴스 변수
    private String instanceVar = "Hello";

    public void method() {
        // Stack (스택) - 지역 변수, 매개변수, 리턴 주소
        int localVar = 20;

        // Heap에 객체 생성, Stack에 참조 저장
        Object obj = new Object();

        // Stack에 primitive 저장
        int[] arr = new int[10]; // 배열 객체는 Heap, 참조는 Stack
    }
}
```

**왜 이렇게 나뉘는가?**
- **Stack**: 함수 호출과 함께 생성/소멸 → LIFO 구조 적합
- **Heap**: 프로그래머가 제어하는 수명 → 동적 할당/해제
- **Method Area**: 클래스 로드 시 한 번만 생성 → 공유

### JVM 메모리 구조

```
┌─────────────────────────────────────────────────────────────┐
│                        JVM Memory                           │
├─────────────────────────────────────────────────────────────┤
│  Method Area (메서드 영역)                                    │
│  - 클래스 메타데이터, static 변수, 상수 풀                      │
├─────────────────────────────────────────────────────────────┤
│  Heap (힙)                                                  │
│  ┌────────────────────┬────────────────────────────────┐    │
│  │   Young Generation │      Old Generation            │    │
│  │  ┌─────┬─────────┐ │                                │    │
│  │  │ Eden│ Survivor│ │      (Tenured)                 │    │
│  │  └─────┴─────────┘ │                                │    │
│  └────────────────────┴────────────────────────────────┘    │
├─────────────────────────────────────────────────────────────┤
│  Stack (스택) - 스레드별 생성                                  │
│  - 지역 변수, 매개변수, 리턴 주소                               │
├─────────────────────────────────────────────────────────────┤
│  PC Register - 스레드별 생성                                  │
├─────────────────────────────────────────────────────────────┤
│  Native Method Stack - 네이티브 메서드 호출 시 사용             │
└─────────────────────────────────────────────────────────────┘
```

**왜 Young/Old로 나뉘는가?**
- **세대별 가설**: 대부분의 객체는 금방 죽음 (Young에서 처리)
- **Young GC**: 빈번하지만 빠름 (작은 영역)
- **Old GC**: 드물지만 오래 걸림 (큰 영역)
- 효율적인 GC를 위한 설계

---

## 트레이드오프

| 기준 | 페이징 | 세그멘테이션 |
|------|--------|-------------|
| 단편화 | 내부 단편화 | 외부 단편화 |
| 관리 복잡도 | ✅ 단순 | ❌ 복잡 |
| 논리적 구조 | ❌ 물리적 분할 | ✅ 논리적 분할 |
| 보호 단위 | 페이지 단위 | 세그먼트 단위 |
| 공유 단위 | 페이지 단위 | 세그먼트 단위 |

### 페이지 크기 선택

| 페이지 크기 | 장점 | 단점 |
|------------|------|------|
| 작은 크기 (4KB) | 내부 단편화 ↓ | 페이지 테이블 ↑ |
| 큰 크기 (2MB) | 페이지 테이블 ↓, TLB 효율 ↑ | 내부 단편화 ↑ |

**현대 시스템 선택:**
- 기본: 4KB (범용)
- Huge Pages: 2MB/1GB (데이터베이스, 가상화)

---

## 면접 예상 질문

### Q: 가상 메모리란 무엇이고, 왜 사용하나요?

**A**: 가상 메모리는 물리 메모리의 크기와 관계없이 프로세스에게 독립적인 주소 공간을 제공하는 메모리 관리 기법입니다.

**왜 사용하는가?**

| 이유 | 설명 | 예시 |
|------|------|------|
| 메모리 추상화 | 각 프로세스가 전체 메모리 독점처럼 동작 | 0번지부터 시작하는 주소 사용 |
| 메모리 보호 | 프로세스 간 메모리 영역 침범 방지 | A가 B 메모리 접근 불가 |
| 메모리 확장 | 물리 메모리보다 큰 프로그램 실행 | 8GB RAM에서 16GB 프로그램 |
| 메모리 공유 | 공유 라이브러리를 여러 프로세스가 공유 | libc.so 한 번만 로드 |

**만약 가상 메모리가 없다면?**
- 모든 프로세스가 물리 주소 직접 사용 → 주소 충돌
- 프로그램마다 다른 주소에서 시작해야 함 → 재컴파일 필요
- 메모리 보호 불가 → 악성코드 천국

---

### Q: 페이징과 세그멘테이션의 차이점은 무엇인가요?

**A**:

| 구분 | 페이징 | 세그멘테이션 |
|------|--------|-------------|
| 분할 단위 | 고정 크기 (Page) | 가변 크기 (Segment) |
| 분할 기준 | 물리적 (크기 기준) | 논리적 (용도 기준) |
| 단편화 | 내부 단편화 | 외부 단편화 |
| 주소 구조 | (페이지 번호, 오프셋) | (세그먼트 번호, 오프셋) |

**왜 현대 OS는 페이징을 선호하는가?**
- 외부 단편화 없음 → 메모리 효율
- 관리 단순 → 구현 용이
- 세그멘테이션의 장점은 페이지 테이블 속성으로 대체 가능 (보호 비트 등)

**만약 세그멘테이션만 사용하면?**
- 메모리 조각화로 할당 실패 빈번
- 메모리 컴팩션 필요 → 시스템 일시 정지

---

### Q: 페이지 폴트가 발생하면 어떤 과정이 일어나나요?

**A**: 페이지 폴트는 접근하려는 페이지가 물리 메모리에 없을 때 발생합니다.

**처리 과정:**
1. **트랩 발생**: CPU가 페이지 폴트 인터럽트 발생
2. **유효성 검사**: OS가 해당 접근이 valid한지 확인 (잘못된 접근이면 프로세스 종료)
3. **빈 프레임 확보**:
   - 빈 프레임이 있으면 사용
   - 없으면 **페이지 교체 알고리즘**으로 victim 페이지 선택
   - victim이 수정되었으면(dirty bit=1) 디스크에 먼저 기록
4. **페이지 적재**: 디스크에서 해당 페이지를 빈 프레임에 로드
5. **테이블 갱신**: 페이지 테이블의 valid bit을 1로 설정
6. **명령어 재실행**: 중단된 명령어부터 다시 실행

**왜 성능에 중요한가?**
- 페이지 폴트는 디스크 I/O 수반 (10만~100만 배 느림)
- 페이지 폴트율 1%만 되어도 시스템 성능 급격히 저하
- 페이지 폴트율이 높아지면 **스레싱** 발생

---

### Q: LRU 알고리즘을 설명하고, 왜 많이 사용되나요?

**A**: LRU(Least Recently Used)는 가장 오랫동안 사용되지 않은 페이지를 교체하는 알고리즘입니다.

**왜 효과적인가?**
- **지역성 원리**: 최근 사용된 것은 또 사용될 확률 높음
- **시간 지역성**: 최근 참조된 데이터 다시 참조
- **공간 지역성**: 인접 데이터 함께 참조
- Optimal 알고리즘에 가장 가까운 실용적 구현

**구현 방법:**

| 방법 | 시간 복잡도 | 장단점 |
|------|------------|--------|
| 타임스탬프 | O(n) 검색 | 간단하지만 느림 |
| 스택 | O(n) 이동 | 페이지 재배치 필요 |
| LinkedHashMap | O(1) | Java에서 가장 효율적 |

**만약 LRU를 안 쓰면?**
- FIFO: Belady's Anomaly 발생 가능 (프레임 늘려도 폴트 증가)
- LFU: 오래 전에 많이 쓰인 페이지가 계속 남음

---

### Q: 스레싱이란 무엇이고, 어떻게 해결하나요?

**A**: 스레싱은 페이지 폴트가 과도하게 발생하여 CPU가 실제 작업보다 페이지 교체에 더 많은 시간을 소비하는 현상입니다.

**왜 발생하는가?**
- 각 프로세스에 할당된 프레임 수 < Working Set 크기
- 너무 많은 프로세스가 메모리 경쟁
- 결과: 한 프로세스가 페이지 가져오면 다른 프로세스 페이지 밀려남 → 연쇄 폴트

**해결 방법:**

| 방법 | 원리 | 효과 |
|------|------|------|
| Working Set | 필요한 최소 프레임 보장 | 각 프로세스 정상 동작 |
| PFF | 폴트율 기반 동적 조절 | 실시간 최적화 |
| 프로세스 Swap Out | 메모리 경쟁 감소 | 남은 프로세스에 충분한 메모리 |

**만약 해결하지 않으면?**
- CPU 100% but 실제 작업 0%
- 시스템 응답 불가 (멈춤 현상)
- 최악의 경우 시스템 재시작 필요

---

## 참고 자료

- Operating System Concepts (Silberschatz)
- Modern Operating Systems (Tanenbaum)
- [Linux Memory Management](https://www.kernel.org/doc/html/latest/admin-guide/mm/index.html)
- Understanding the Linux Virtual Memory Manager (Mel Gorman)
