# 프로세스 vs 스레드

> `Beginner` 입문 · 선수 지식 없음

> 프로세스는 실행 중인 프로그램의 독립적인 인스턴스이고, 스레드는 프로세스 내에서 실행되는 작업의 단위이다.

`#프로세스` `#Process` `#스레드` `#Thread` `#멀티스레드` `#Multithreading` `#컨텍스트스위칭` `#ContextSwitching` `#동시성` `#Concurrency` `#병렬처리` `#Parallelism` `#PCB` `#ProcessControlBlock` `#TCB` `#ThreadControlBlock` `#IPC` `#InterProcessCommunication` `#RaceCondition` `#Deadlock` `#synchronized` `#Lock` `#Atomic` `#ExecutorService` `#ThreadPool` `#Runnable` `#fork` `#TLB플러시` `#멀티프로세스` `#Multiprocess`

## 왜 알아야 하는가?

멀티스레딩은 현대 애플리케이션의 기본입니다. 웹 서버가 동시에 수천 개의 요청을 처리하고, 모바일 앱이 UI를 멈추지 않고 백그라운드 작업을 수행하는 것은 모두 프로세스와 스레드 개념을 기반으로 합니다. Race Condition, Deadlock 같은 동시성 버그는 이 개념을 정확히 이해하지 못하면 디버깅이 거의 불가능합니다.

**실무 연관성:**
- 백엔드 개발: 멀티스레드 서버 설계, 스레드 풀 관리
- 동시성 제어: synchronized, Lock, AtomicXxx 활용
- 성능 최적화: 적절한 스레드 수 선택, 컨텍스트 스위칭 최소화
- 시스템 설계: 멀티프로세스 vs 멀티스레드 아키텍처 선택

## 핵심 개념

- **프로세스**: 독립된 메모리 공간(Code, Data, Stack, Heap)을 가진 실행 단위
- **스레드**: 프로세스 내에서 Stack만 독립적으로 할당받고, 나머지는 공유하는 실행 단위
- **컨텍스트 스위칭**: 프로세스 전환이 스레드 전환보다 비용이 큼
- **멀티프로세스 vs 멀티스레드**: 안정성 vs 효율성의 트레이드오프

## 쉽게 이해하기

**프로세스와 스레드**를 공장에 비유할 수 있습니다.

### 프로세스 = 독립된 공장

각 공장(프로세스)은 자체 건물, 기계, 창고, 사무실을 갖고 있습니다. 공장끼리는 완전히 분리되어 있어서 한 공장에 화재가 나도 다른 공장은 영향을 받지 않습니다. 하지만 공장 간에 물건을 주고받으려면 트럭으로 운송해야 합니다(IPC).

### 스레드 = 공장 안의 작업자들

한 공장 안에 여러 작업자(스레드)가 있습니다. 작업자들은 같은 기계와 창고를 공유하면서 각자 다른 일을 합니다. 작업자 간에 물건을 주고받기는 쉽지만(메모리 공유), 한 작업자가 기계를 망가뜨리면 모든 작업자가 일을 못 하게 됩니다.

| 비유 | 프로세스 | 스레드 |
|------|---------|--------|
| 공장 건물 | 독립된 메모리 공간 | 공유 |
| 개인 작업대 | - | Stack (독립) |
| 공장 간 운송 | IPC (복잡) | 메모리 공유 (간단) |
| 화재 발생 시 | 해당 공장만 피해 | 전체 공장 피해 |

### 컨텍스트 스위칭 = 작업 전환

- **프로세스 전환**: 완전히 다른 공장으로 출근하는 것 (시간 오래 걸림)
- **스레드 전환**: 같은 공장에서 다른 작업대로 이동하는 것 (빠름)

**왜 이렇게 차이가 나나요?**
- 프로세스 전환: 메모리 맵, 캐시(TLB), 레지스터 **전부** 교체해야 함
- 스레드 전환: 같은 메모리 공간 내에서 Stack 포인터, 레지스터**만** 교체

---

## 상세 설명

### 프로세스 (Process)

프로세스는 운영체제로부터 자원을 할당받는 작업의 단위이다.

```
┌─────────────────────────────┐
│         Process             │
├─────────────────────────────┤
│  Code   │ 실행할 프로그램 코드 │
├─────────────────────────────┤
│  Data   │ 전역 변수, 정적 변수 │
├─────────────────────────────┤
│  Heap   │ 동적 할당 메모리    │
├─────────────────────────────┤
│  Stack  │ 지역 변수, 함수 호출 │
└─────────────────────────────┘
```

**특징:**
- 각 프로세스는 독립된 메모리 공간을 가짐
- 프로세스 간 통신(IPC)이 필요: 파이프, 소켓, 공유 메모리 등
- 하나의 프로세스가 죽어도 다른 프로세스에 영향 없음

**왜 독립된 메모리 공간인가?**
- **보안**: 다른 프로세스의 메모리를 임의로 접근하면 악성코드가 될 수 있음
- **안정성**: 한 프로세스의 버그가 다른 프로세스를 죽이면 시스템 전체가 불안정
- **추상화**: 각 프로세스가 전체 메모리를 독점하는 것처럼 프로그래밍 가능

### 스레드 (Thread)

스레드는 프로세스 내에서 실행되는 흐름의 단위이다.

```
┌─────────────────────────────────────┐
│              Process                │
├─────────────────────────────────────┤
│  Code (공유)  │  Data (공유)  │  Heap (공유)  │
├─────────────────────────────────────┤
│  Thread 1   │  Thread 2   │  Thread 3   │
│  ┌───────┐  │  ┌───────┐  │  ┌───────┐  │
│  │ Stack │  │  │ Stack │  │  │ Stack │  │
│  └───────┘  │  └───────┘  │  └───────┘  │
└─────────────────────────────────────┘
```

**특징:**
- Stack만 독립적으로 할당, Code/Data/Heap은 공유
- 스레드 간 통신이 간단 (메모리 공유)
- 하나의 스레드 문제가 전체 프로세스에 영향

**왜 Stack만 독립적인가?**
- **Stack**: 함수 호출 흐름(지역 변수, 리턴 주소)은 스레드마다 다름 → 독립 필수
- **Code**: 같은 프로그램이므로 공유해도 됨
- **Data/Heap**: 스레드 간 데이터 공유를 위해 공유 (통신 용이)

---

## 프로세스 vs 스레드 비교

| 구분 | 프로세스 | 스레드 |
|------|---------|--------|
| 메모리 | 독립적 | Stack만 독립, 나머지 공유 |
| 생성 비용 | 높음 | 낮음 |
| 컨텍스트 스위칭 | 무거움 (메모리 전환) | 가벼움 (Stack만 전환) |
| 통신 | IPC 필요 | 메모리 공유로 간단 |
| 안정성 | 높음 (격리) | 낮음 (공유 자원 문제) |
| 동기화 | 불필요 | 필요 (Race Condition) |

### 왜 이런 차이가 발생하는가?

**생성 비용:**
- 프로세스: OS가 새 메모리 공간, 페이지 테이블, PCB 등을 모두 새로 생성
- 스레드: 기존 프로세스 자원 대부분 공유, Stack과 TCB만 새로 생성

**컨텍스트 스위칭:**
- 프로세스: 메모리 맵 전환 → TLB 플러시 → 캐시 미스 급증
- 스레드: 같은 메모리 공간 → TLB 유지 → 캐시 효율 유지

**만약 잘못 선택하면?**
- 독립성이 필요한데 스레드 사용 → 한 스레드 죽으면 전체 서비스 다운
- 통신이 많은데 프로세스 사용 → IPC 오버헤드로 성능 저하

---

## 컨텍스트 스위칭 (Context Switching)

CPU가 현재 작업을 멈추고 다른 작업으로 전환하는 과정.

### 프로세스 컨텍스트 스위칭

```
1. 현재 프로세스 상태를 PCB(Process Control Block)에 저장
   - 레지스터, 프로그램 카운터, 스택 포인터
   - 메모리 맵, 열린 파일 목록

2. 다음 프로세스의 PCB에서 상태 복원

3. 메모리 맵, 캐시 등 전체 전환 필요
   - TLB 플러시 (가상 주소 → 물리 주소 캐시 무효화)
   - 캐시 미스율 증가
```

**왜 비용이 큰가?**
- TLB 플러시: 주소 변환 캐시가 무효화되어 다시 채워야 함
- CPU 캐시: 이전 프로세스 데이터가 캐시에 있어 miss 발생
- 메모리 접근: 페이지 테이블 변경으로 첫 접근이 느림

### 스레드 컨텍스트 스위칭

```
1. 현재 스레드의 레지스터, Stack 포인터 저장

2. 다음 스레드의 레지스터, Stack 포인터 복원

3. 같은 프로세스 내라면 메모리 전환 불필요
   - TLB 유지 (같은 주소 공간)
   - 캐시 효율 유지
```

**왜 비용이 적은가?**
- 같은 주소 공간: TLB, 페이지 테이블 변경 불필요
- 캐시 유지: Code/Data 공유로 캐시 히트율 높음
- 저장 정보 최소: 레지스터와 Stack 포인터만 저장

---

## 멀티프로세스 vs 멀티스레드

### 멀티프로세스

**권장 (O): 격리와 안정성이 중요한 경우**

```java
// Chrome 브라우저 - 탭별 프로세스
// 한 탭이 죽어도 다른 탭은 정상 동작

// 마이크로서비스 아키텍처
// 서비스별 독립 프로세스로 장애 격리
```

**장점:**
- 안정성: 하나가 죽어도 다른 프로세스 정상
- 보안: 프로세스 간 메모리 격리
- 확장성: 멀티코어에서 진정한 병렬 실행

**단점:**
- 메모리 사용량 증가 (각 프로세스가 독립 공간)
- IPC 오버헤드 (프로세스 간 통신 비용)
- 생성/전환 비용 높음

**만약 지키지 않으면?**
- 메모리 부족: 프로세스당 수십~수백 MB 소비
- IPC 병목: 프로세스 간 대량 데이터 전송 시 성능 저하
- 복잡성 증가: 분산 시스템처럼 동기화 문제 발생

### 멀티스레드

**권장 (O): 자원 공유와 통신이 많은 경우**

```java
// 웹 서버 - 요청별 스레드
// 공유 캐시, 커넥션 풀 등 자원 효율적 활용

// GUI 애플리케이션
// UI 스레드 + 백그라운드 작업 스레드
```

**장점:**
- 자원 효율: 메모리 공유로 중복 없음
- 통신 간단: 메모리 공유로 즉시 접근
- 빠른 생성/전환: 오버헤드 최소

**단점:**
- 동기화 문제: Race Condition, Deadlock
- 하나의 스레드 오류가 전체 영향
- 디버깅 어려움

**만약 지키지 않으면?**
- Race Condition: 공유 자원 동시 접근으로 데이터 오염
- Deadlock: 잘못된 락 순서로 무한 대기
- 전체 프로세스 크래시: 한 스레드의 null pointer로 서비스 전체 다운

---

## 동기화 문제와 해결

### 문제가 되는 패턴

**비권장 (X): 동기화 없는 공유 자원 접근**

```java
// Race Condition 발생
public class Counter {
    private int count = 0;  // 공유 자원

    public void increment() {
        count++;  // read → modify → write (3단계)
        // Thread A: read count (0)
        // Thread B: read count (0)
        // Thread A: write count (1)
        // Thread B: write count (1) ← 2가 아니라 1!
    }
}
```

**왜 문제인가?**
- `count++`은 원자적(atomic) 연산이 아님
- 중간에 다른 스레드가 끼어들 수 있음
- 결과: 데이터 정합성 깨짐

### 권장 설계

**권장 (O): 적절한 동기화 적용**

```java
public class Counter {
    private int count = 0;

    // synchronized로 동기화
    public synchronized void increment() {
        count++;
    }

    // 또는 AtomicInteger 사용
    private AtomicInteger atomicCount = new AtomicInteger(0);

    public void incrementAtomic() {
        atomicCount.incrementAndGet();  // 원자적 연산
    }
}
```

**왜 이렇게 하는가?**
1. **synchronized**: 한 번에 하나의 스레드만 메서드 실행
2. **AtomicInteger**: CAS(Compare-And-Swap) 연산으로 락 없이 원자성 보장

---

## 예제 코드

### Java에서 스레드 생성

```java
// 1. Thread 클래스 상속
class MyThread extends Thread {
    @Override
    public void run() {
        System.out.println("Thread: " + Thread.currentThread().getName());
    }
}

// 2. Runnable 인터페이스 구현 (권장)
class MyRunnable implements Runnable {
    @Override
    public void run() {
        System.out.println("Runnable: " + Thread.currentThread().getName());
    }
}

// 실행
public class ThreadExample {
    public static void main(String[] args) {
        // Thread 상속
        new MyThread().start();

        // Runnable 구현 (권장 - 다른 클래스 상속 가능)
        new Thread(new MyRunnable()).start();

        // Lambda (Java 8+, 가장 간결)
        new Thread(() -> {
            System.out.println("Lambda: " + Thread.currentThread().getName());
        }).start();
    }
}
```

**왜 Runnable이 권장되는가?**
- Java는 단일 상속 → Thread 상속하면 다른 클래스 상속 불가
- Runnable은 인터페이스 → 다른 클래스 상속과 병행 가능
- 실행 로직(Runnable)과 실행 메커니즘(Thread) 분리

### ExecutorService 사용 (권장)

```java
// 스레드 풀 사용 - 스레드 생성/제거 오버헤드 최소화
ExecutorService executor = Executors.newFixedThreadPool(10);

for (int i = 0; i < 100; i++) {
    executor.submit(() -> {
        // 작업 수행
        System.out.println(Thread.currentThread().getName());
    });
}

executor.shutdown();  // 작업 완료 후 종료
```

**왜 ExecutorService를 사용하는가?**
- 스레드 재사용: 생성/제거 비용 절감
- 자원 관리: 스레드 수 제한으로 시스템 보호
- 작업 큐: 작업이 스레드보다 많으면 대기열에 저장

---

## 트레이드오프

| 기준 | 멀티프로세스 | 멀티스레드 |
|------|-------------|-----------|
| 격리/안정성 | ✅ 우수 | ❌ 취약 |
| 메모리 효율 | ❌ 중복 | ✅ 공유 |
| 통신 용이성 | ❌ IPC 필요 | ✅ 메모리 공유 |
| 생성/전환 비용 | ❌ 높음 | ✅ 낮음 |
| 동기화 복잡도 | ✅ 불필요 | ❌ 필수 |
| 디버깅 | ✅ 쉬움 | ❌ 어려움 |

### 선택 가이드

| 상황 | 권장 | 이유 |
|------|------|------|
| 브라우저 탭 | 멀티프로세스 | 한 탭 크래시 → 다른 탭 영향 없음 |
| 웹 서버 요청 처리 | 멀티스레드 | 커넥션 풀, 캐시 공유 효율 |
| 배치 작업 | 멀티프로세스 | 독립 실행, 부분 실패 허용 |
| GUI + 백그라운드 | 멀티스레드 | 같은 데이터 공유, 빠른 통신 |
| 마이크로서비스 | 멀티프로세스 | 서비스 격리, 독립 배포 |

---

## 면접 예상 질문

### Q: 프로세스와 스레드의 차이점은?

**A:** 프로세스는 독립된 메모리 공간을 가진 실행 단위이고, 스레드는 프로세스 내에서 Stack만 독립적으로 갖고 Code/Data/Heap을 공유하는 실행 단위입니다.

**왜 이런 구조인가?**
- **프로세스 독립**: 보안과 안정성을 위해 OS가 격리
- **스레드 공유**: 같은 프로그램 실행이므로 Code/Data 공유해도 문제 없음
- **Stack 독립**: 각 스레드의 실행 흐름(함수 호출)은 독립적이어야 함

**만약 스레드가 모든 것을 공유하면?**
- 함수 호출 시 지역 변수가 섞여 혼란
- 한 스레드의 함수 리턴이 다른 스레드 흐름에 영향

---

### Q: 멀티프로세스 대신 멀티스레드를 사용하는 이유는?

**A:** 스레드는 메모리를 공유하므로 자원 효율이 좋고, 컨텍스트 스위칭 비용이 적으며, 스레드 간 통신이 간단합니다.

**왜 비용이 적은가?**
- 프로세스 전환: TLB 플러시, 페이지 테이블 변경, 캐시 무효화
- 스레드 전환: 레지스터, Stack 포인터만 저장/복원

**만약 멀티스레드가 항상 좋다면?**
- 동기화 비용: Lock 경쟁으로 오히려 느려질 수 있음
- 안정성 문제: 한 스레드 버그로 전체 프로세스 크래시
- 결론: **용도에 따라 선택** (격리 필요 → 프로세스, 공유 필요 → 스레드)

---

### Q: 컨텍스트 스위칭이란?

**A:** CPU가 현재 실행 중인 작업의 상태를 저장하고, 다른 작업의 상태를 복원하여 전환하는 과정입니다.

**왜 프로세스 전환이 더 비싼가?**

| 단계 | 프로세스 전환 | 스레드 전환 |
|------|-------------|-----------|
| 레지스터 저장/복원 | ✅ 필요 | ✅ 필요 |
| Stack 전환 | ✅ 필요 | ✅ 필요 |
| 페이지 테이블 변경 | ✅ 필요 | ❌ 불필요 |
| TLB 플러시 | ✅ 필요 | ❌ 불필요 |
| 캐시 무효화 | 높음 | 낮음 |

**만약 컨텍스트 스위칭이 과도하면?**
- CPU 시간 낭비: 실제 작업보다 전환에 더 많은 시간 소비
- 스래싱(Thrashing): 메모리와 유사하게 CPU도 과도한 전환으로 성능 저하
- 해결: 적절한 스레드/프로세스 수 유지, I/O 멀티플렉싱 활용

---

### Q: Race Condition이란? 어떻게 해결하나요?

**A:** 여러 스레드가 공유 자원에 동시 접근하여 실행 순서에 따라 결과가 달라지는 문제입니다.

**왜 발생하는가?**
- 읽기-수정-쓰기 연산이 원자적이지 않음
- Thread A가 읽고 수정하는 사이에 Thread B가 끼어듦

**해결 방법:**

| 방법 | 설명 | 장단점 |
|------|------|--------|
| synchronized | 한 번에 하나의 스레드만 접근 | 간단하지만 성능 저하 |
| ReentrantLock | 명시적 락, 더 많은 제어 | 유연하지만 복잡 |
| AtomicXxx | CAS 기반 원자적 연산 | 락 없이 빠름, 단순 연산만 |
| volatile | 가시성 보장 | 원자성은 보장 안 함 |

**만약 해결하지 않으면?**
- 데이터 정합성 깨짐 (잔고가 음수, 재고가 맞지 않음)
- 간헐적 버그: 재현 어렵고 디버깅 난이도 극상
- 보안 취약점: TOCTOU(Time-of-check to time-of-use) 공격

---

## 연관 문서

이 문서를 읽은 후 다음 주제를 학습하세요.

| 문서 | 연관성 | 난이도 |
|------|--------|--------|
| [파일 디스크립터](./file-descriptor.md) | FD 테이블은 프로세스별로 관리됨 | Intermediate |
| [파일시스템](./file-system.md) | 프로세스가 파일에 접근하는 방식 | Intermediate |
| [메모리 관리](./memory-management.md) | 프로세스 메모리 구조의 심화 학습 | Advanced |

## 참고 자료

- Operating System Concepts (Silberschatz)
- [Oracle Java Thread Documentation](https://docs.oracle.com/javase/tutorial/essential/concurrency/)
- Java Concurrency in Practice (Brian Goetz)
