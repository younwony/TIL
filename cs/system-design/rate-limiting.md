# Rate Limiting

> `[3] 중급` · 선수 지식: [시스템 설계란](./what-is-system-design.md)

> 일정 시간 동안 허용되는 요청 수를 제한하여 시스템을 보호하는 기법

`#RateLimiting` `#처리율제한` `#트래픽제어` `#TokenBucket` `#토큰버킷` `#LeakyBucket` `#누수버킷` `#SlidingWindow` `#슬라이딩윈도우` `#FixedWindow` `#고정윈도우` `#API제한` `#DDoS` `#서비스보호` `#Redis` `#Throttling` `#스로틀링` `#429` `#TooManyRequests`

## 왜 알아야 하는가?

Rate Limiting은 시스템을 과부하로부터 보호하는 첫 번째 방어선입니다. 악의적인 공격(DDoS), 버그로 인한 과다 요청, 특정 사용자의 독점 사용을 방지합니다. API 서비스라면 반드시 Rate Limiting을 구현해야 합니다.

## 핵심 개념

- **Rate Limiting**: 단위 시간당 요청 수 제한
- **토큰 버킷**: 토큰이 있을 때만 요청 처리
- **슬라이딩 윈도우**: 이동하는 시간 창으로 요청 수 계산
- **429 Too Many Requests**: 제한 초과 시 HTTP 상태 코드

## 쉽게 이해하기

**Rate Limiting**을 놀이공원 입장에 비유할 수 있습니다.

- **고정 윈도우**: 1시간마다 100명 입장 (정각 리셋)
- **슬라이딩 윈도우**: 최근 1시간 동안 100명 제한
- **토큰 버킷**: 입장권 100장, 10분마다 10장 충전
- **누수 버킷**: 분당 10명씩 일정 속도로 입장

## 상세 설명

### Rate Limiting이 필요한 이유

```
┌─────────────────────────────────────────────────────────────┐
│                    Rate Limiting 효과                        │
├─────────────────────────────────────────────────────────────┤
│ 1. DDoS 공격 방어: 악의적인 대량 요청 차단                    │
│ 2. 서비스 안정성: 과부하로 인한 장애 방지                     │
│ 3. 공정한 사용: 특정 사용자의 독점 방지                       │
│ 4. 비용 제어: 클라우드 리소스 비용 관리                       │
│ 5. API 상품화: 유료 플랜별 차등 제한                          │
└─────────────────────────────────────────────────────────────┘
```

### 알고리즘 1: 고정 윈도우 (Fixed Window)

**원리**: 고정된 시간 윈도우마다 카운터 리셋

```
시간: 0초 ─────────────────── 60초 ─────────────────── 120초
      │     윈도우 1 (100/분) │     윈도우 2 (100/분)  │
      │                      │                       │
요청: ████████████████████████│████████████████████████│
      80개 (허용)           │ 50개 (허용)            │
                     ↑      │
                59초에 80개  │
                60초에 80개  │ ← 1초 사이에 160개 가능!
```

**장점**: 구현 간단, 메모리 효율적
**단점**: 윈도우 경계에서 버스트 발생 가능

```java
// Redis 구현
public boolean isAllowed(String userId) {
    String key = "rate:" + userId + ":" + (System.currentTimeMillis() / 60000);
    Long count = redis.incr(key);
    if (count == 1) {
        redis.expire(key, 60);
    }
    return count <= 100;
}
```

### 알고리즘 2: 슬라이딩 로그 (Sliding Log)

**원리**: 모든 요청 타임스탬프 저장, 윈도우 내 요청 수 계산

```
현재 시간: 10:01:30
윈도우: 최근 1분

저장된 로그:
10:00:25 ← 윈도우 밖, 제거
10:00:45 ← 윈도우 내
10:01:00 ← 윈도우 내
10:01:15 ← 윈도우 내
10:01:28 ← 윈도우 내

요청 수: 4개
```

**장점**: 정확한 제한
**단점**: 메모리 사용량 높음

### 알고리즘 3: 슬라이딩 윈도우 카운터 (Sliding Window Counter)

**원리**: 이전 윈도우와 현재 윈도우의 가중 평균

```
이전 윈도우 (10:00-10:01): 80개
현재 윈도우 (10:01-10:02): 40개
현재 시간: 10:01:30 (현재 윈도우 50% 경과)

가중치 계산:
이전 윈도우: 80 × 0.5 = 40
현재 윈도우: 40 × 1.0 = 40
총 요청 수: 80개
```

**장점**: 정확도와 효율성의 균형
**단점**: 완벽하게 정확하지는 않음

### 알고리즘 4: 토큰 버킷 (Token Bucket)

**원리**: 버킷에 토큰이 있으면 요청 허용, 일정 속도로 토큰 충전

```
버킷 용량: 10개
충전 속도: 1개/초
초기 토큰: 10개

시간 0초: 토큰 10개, 요청 5개 → 토큰 5개 남음
시간 1초: 토큰 6개 (충전 +1), 요청 3개 → 토큰 3개 남음
시간 2초: 토큰 4개 (충전 +1), 요청 0개 → 토큰 4개 남음
...
시간 10초: 토큰 10개 (최대), 버스트 요청 10개 가능!
```

```java
class TokenBucket {
    private final int capacity;      // 버킷 용량
    private final int refillRate;    // 초당 충전량
    private double tokens;           // 현재 토큰
    private long lastRefillTime;     // 마지막 충전 시간

    public synchronized boolean tryConsume() {
        refill();
        if (tokens >= 1) {
            tokens--;
            return true;
        }
        return false;
    }

    private void refill() {
        long now = System.currentTimeMillis();
        double tokensToAdd = (now - lastRefillTime) / 1000.0 * refillRate;
        tokens = Math.min(capacity, tokens + tokensToAdd);
        lastRefillTime = now;
    }
}
```

**장점**: 버스트 트래픽 허용, 평균 처리율 유지
**단점**: 분산 환경에서 동기화 필요

### 알고리즘 5: 누수 버킷 (Leaky Bucket)

**원리**: 요청을 큐에 넣고 일정 속도로 처리

```
버킷 용량: 10개
처리 속도: 2개/초

요청 5개 도착 → 큐: [1,2,3,4,5]
1초 후: 큐: [3,4,5] (2개 처리)
요청 8개 도착 → 큐: [3,4,5,6,7,8,9,10] (8개 대기)
요청 5개 도착 → 큐 가득 참, 3개 버림!
```

**장점**: 일정한 출력 속도, 트래픽 평활화
**단점**: 버스트 트래픽 처리 불가, 지연 발생

### 알고리즘 비교

| 알고리즘 | 정확도 | 메모리 | 버스트 허용 | 구현 복잡도 |
|---------|--------|--------|-----------|------------|
| 고정 윈도우 | 낮음 | 낮음 | O (경계) | 낮음 |
| 슬라이딩 로그 | 높음 | 높음 | X | 중간 |
| 슬라이딩 윈도우 | 중간 | 낮음 | X | 중간 |
| 토큰 버킷 | 높음 | 낮음 | O | 중간 |
| 누수 버킷 | 높음 | 중간 | X | 중간 |

### 분산 환경에서의 Rate Limiting

```
┌─────────────┐
│  클라이언트  │
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 로드밸런서   │
└──────┬──────┘
       │
  ┌────┴────┐
  │         │
┌─▼──┐   ┌──▼─┐
│서버1│   │서버2│  ← 각 서버가 별도로 카운트하면?
└─┬──┘   └──┬─┘     → 전체 200/분 허용됨!
  │         │
  └────┬────┘
       │
  ┌────▼────┐
  │  Redis  │  ← 중앙 집중식 카운터로 해결
  └─────────┘
```

### 응답 헤더

```http
HTTP/1.1 200 OK
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 45
X-RateLimit-Reset: 1640000000

HTTP/1.1 429 Too Many Requests
Retry-After: 30
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1640000060
```

## 트레이드오프

| 항목 | 엄격한 제한 | 느슨한 제한 |
|------|-----------|-----------|
| 보안 | 강함 | 약함 |
| 사용자 경험 | 나쁨 | 좋음 |
| 리소스 보호 | 확실 | 불확실 |

## 면접 예상 질문

### Q: Rate Limiting을 왜 사용하나요?

A: (1) **DDoS 방어**: 악의적인 대량 요청 차단 (2) **서비스 안정성**: 과부하 방지 (3) **공정한 사용**: 특정 사용자 독점 방지 (4) **비용 제어**: 클라우드 리소스 비용 관리. **실무에서는** API Gateway 레벨에서 적용하고, Redis로 분산 환경에서도 정확한 카운팅을 합니다.

### Q: 토큰 버킷과 누수 버킷의 차이는?

A: **토큰 버킷**은 버스트 트래픽을 허용합니다. 토큰이 쌓여있으면 한 번에 많이 처리 가능합니다. **누수 버킷**은 일정 속도로만 처리하여 출력을 평활화합니다. **선택 기준**: 순간적인 트래픽 급증을 허용하려면 토큰 버킷, 백엔드 부하를 일정하게 유지하려면 누수 버킷을 사용합니다.

## 연관 문서

| 문서 | 연관성 | 난이도 |
|------|--------|--------|
| [시스템 설계란](./what-is-system-design.md) | 선수 지식 | [1] 정의 |

## 참고 자료

- [Redis Rate Limiting](https://redis.io/commands/incr#pattern-rate-limiter)
- System Design Interview - Alex Xu
