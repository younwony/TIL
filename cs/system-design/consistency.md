# 일관성 (Consistency)

> `[3] 중급` · 선수 지식: [가용성](./availability.md), 분산 시스템 기초

> 분산 시스템에서 모든 노드가 동일한 데이터를 보는 상태

## 왜 알아야 하는가?

- **실무**: 분산 시스템에서 CAP 정리는 설계의 핵심. CP vs AP 선택이 시스템 특성 결정
- **면접**: "강한 일관성과 최종 일관성 차이", "CAP 정리" 필수 질문
- **기반 지식**: 분산 DB, 마이크로서비스 아키텍처의 이론적 기초

## 핵심 개념

- **일관성 (Consistency)**: 모든 클라이언트가 동일한 시점에 동일한 데이터를 읽는 것을 보장
- **강한 일관성 (Strong Consistency)**: 쓰기 후 즉시 모든 노드에서 최신 데이터를 읽을 수 있음
- **최종 일관성 (Eventual Consistency)**: 쓰기 후 일정 시간이 지나면 모든 노드가 일관된 상태에 도달
- **분산 시스템 일관성**: 네트워크 지연과 장애 상황에서 데이터 정합성을 유지하는 방법
- **CAP 정리**: 일관성(C), 가용성(A), 분할 내성(P) 중 2개만 선택 가능
- **일관성 모델**: 데이터 동기화 수준에 따른 다양한 일관성 스펙트럼

## 쉽게 이해하기

**일관성**을 여러 지점을 둔 은행 통장에 비유할 수 있습니다.

### 강한 일관성 = 실시간 통장 잔액

```
서울 지점에서 10만원 출금:
├── 출금 즉시 모든 지점 시스템에 반영
└── 부산 지점에서 조회 시 즉시 반영된 잔액 확인

예: 잔액 100만원 → 서울에서 10만원 출금
    → 부산에서 즉시 90만원으로 조회됨

장점: 정확함
단점: 느림 (모든 지점 동기화 대기)
```

### 최종 일관성 = 하루 마감 통장

```
서울 지점에서 10만원 출금:
├── 서울 지점만 즉시 반영
└── 부산 지점은 하루 마감 후 반영

예: 잔액 100만원 → 서울에서 오전 10시에 10만원 출금
    → 서울: 즉시 90만원
    → 부산: 오후 6시까지 100만원으로 보임
         → 마감 후: 90만원으로 갱신

장점: 빠름
단점: 일시적으로 틀린 정보
```

### 실생활 예시

| 상황 | 일관성 수준 | 이유 |
|------|----------|------|
| **ATM 출금** | 강한 일관성 | 잔액 부족인데 출금되면 안 됨 |
| **콘서트 티켓 예매** | 강한 일관성 | 좌석이 중복 판매되면 안 됨 |
| **SNS 좋아요 수** | 최종 일관성 | 약간 다르게 보여도 괜찮음 |
| **배달 앱 리뷰** | 최종 일관성 | 몇 초 후에 보여도 괜찮음 |
| **쇼핑몰 재고** | 강한 일관성 | 재고 없는데 주문받으면 안 됨 |

### 편의점 재고 관리로 이해하기

```
[강한 일관성] - 본사 실시간 연동
┌──────────────┐         ┌──────────────┐
│  강남점      │         │   본사 시스템 │
│  컵라면 -1개 │ ──실시간─▶│  전체 재고   │
└──────────────┘  동기화  └──────┬───────┘
                                 │ 동기화 완료 후
                                 │ 판매 완료 처리
┌──────────────┐         ┌───────▼───────┐
│  잠실점      │◀────────│  즉시 반영    │
│  최신 재고   │  조회    │  컵라면 -1개  │
└──────────────┘         └───────────────┘

특징: 정확하지만 네트워크 지연 발생


[최종 일관성] - 배치 동기화
┌──────────────┐         ┌──────────────┐
│  강남점      │         │   본사 시스템 │
│  컵라면 -1개 │ ─배치─▶ │  (1시간 후)  │
│  즉시 판매   │         └──────────────┘
└──────────────┘

┌──────────────┐
│  잠실점      │
│  구 재고 조회│ ← 1시간 동안 이전 재고로 보임
│  (정합성X)   │
└──────────────┘
         │
         ▼ (1시간 후 배치 동기화)
┌──────────────┐
│  잠실점      │
│  최신 재고   │ ← 최종적으로는 일관됨
└──────────────┘

특징: 빠르지만 일시적 불일치
```

## 상세 설명

### 1. 일관성 모델 스펙트럼

```
강한 일관성 ◀──────────────────────────────────▶ 약한 일관성
(Strong)                                         (Weak)

  │            │            │            │            │
  ▼            ▼            ▼            ▼            ▼
┌────────┬─────────┬─────────┬──────────┬──────────────┐
│선형화   │순차적   │인과적   │세션      │최종          │
│가능     │일관성   │일관성   │일관성    │일관성        │
│        │         │         │          │              │
│Lineari-│Sequential│Causal  │Session   │Eventual      │
│zability│         │         │          │              │
└────────┴─────────┴─────────┴──────────┴──────────────┘
    │            │            │            │            │
    ▼            ▼            ▼            ▼            ▼
 가장 엄격    엄격함      중간       느슨함      가장 느슨
 성능 낮음                                   성능 높음
 가용성 낮음                                 가용성 높음
```

**일관성 모델 비교:**

| 모델 | 보장 내용 | 예시 | 사용처 |
|------|----------|------|--------|
| **선형화 가능 (Linearizability)** | 모든 연산이 전역적으로 단일 시간선상에서 원자적으로 실행됨 | 시계열 DB | 분산 락, 리더 선출 |
| **순차적 일관성 (Sequential)** | 모든 프로세스가 동일한 순서로 연산을 봄 | 멀티코어 메모리 모델 | 공유 메모리 시스템 |
| **인과적 일관성 (Causal)** | 인과 관계 있는 연산은 모든 노드에서 같은 순서로 보임 | 댓글 → 답글 | 협업 도구 |
| **세션 일관성 (Session)** | 같은 세션 내에서는 일관성 보장 | 쇼핑 카트 | 웹 애플리케이션 |
| **최종 일관성 (Eventual)** | 쓰기가 없으면 결국 모든 노드가 수렴 | DNS | SNS, 로그 수집 |

### 2. 강한 일관성 (Strong Consistency)

**정의:**
쓰기 연산이 완료된 후, 모든 후속 읽기 연산은 항상 최신 값을 읽음.

```
시간 ──────────────────────────────────────▶

노드1: Write(x=10) ───┐
                      │ 동기화
노드2:                └───▶ Read(x) → 10 ✓
노드3:                └───▶ Read(x) → 10 ✓

모든 노드가 항상 동일한 최신값 반환
```

**구현 방법:**

**(1) 동기식 레플리케이션 (Synchronous Replication)**

```
┌──────────────────────────────────────────────────────────┐
│                   동기식 쓰기 과정                        │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  Client                                                  │
│    │                                                     │
│    │ Write(x=10)                                        │
│    ▼                                                     │
│  ┌────────┐                                             │
│  │ Master │                                             │
│  └────┬───┘                                             │
│       │                                                  │
│       ├──────────────┐                                  │
│       │              │                                  │
│       ▼              ▼                                  │
│  ┌────────┐     ┌────────┐                             │
│  │Replica1│     │Replica2│                             │
│  └────┬───┘     └────┬───┘                             │
│       │              │                                  │
│       │ ACK          │ ACK                              │
│       ▼              ▼                                  │
│  ┌────────┐     모든 Replica                           │
│  │ Master │◀────쓰기 완료 후                            │
│  └────┬───┘                                             │
│       │                                                  │
│       │ Success                                          │
│       ▼                                                  │
│    Client ← 이때 성공 응답                               │
│                                                          │
└──────────────────────────────────────────────────────────┘

쓰기 지연: Master 지연 + 네트워크 지연 + Replica 지연
예: 10ms + 5ms + 10ms = 25ms (비동기 대비 2배 이상)
```

**(2) 분산 합의 알고리즘 (Consensus Algorithm)**

```java
// Raft 알고리즘 기반 강한 일관성 구현 예시
public class RaftConsensus {
    private List<Node> nodes;
    private Node leader;

    // 쓰기 요청은 리더만 처리
    public void write(String key, String value) {
        if (!isLeader()) {
            throw new NotLeaderException("리더가 아님");
        }

        // 1. 로그에 기록
        LogEntry entry = new LogEntry(key, value);
        appendLog(entry);

        // 2. 과반수 노드에 복제
        int ackCount = 1; // 리더 자신
        for (Node node : nodes) {
            if (node.appendEntry(entry)) {
                ackCount++;
            }
        }

        // 3. 과반수 확인 후 커밋
        if (ackCount > nodes.size() / 2) {
            commitLog(entry);
            return; // 성공
        } else {
            rollbackLog(entry);
            throw new ConsensusFailedException();
        }
    }

    // 읽기는 항상 커밋된 데이터만 반환
    public String read(String key) {
        return getCommittedValue(key);
    }
}
```

**왜 이렇게 하는가?**
- 데이터 정합성 보장: 중복 결제, 재고 초과 판매 방지
- 사용자 혼란 방지: A 사용자가 수정한 내용을 B 사용자가 바로 확인 가능
- 법적 요구사항: 금융, 의료 등 규제 산업에서 필수

**만약 지키지 않으면?**
- 중복 결제: A 노드는 잔액 1만원, B 노드는 10만원 → 동시 출금 시 초과 인출
- 재고 초과 판매: 재고 1개인데 2명이 다른 노드에서 주문 성공
- 데이터 유실: Primary 쓰기 후 Replica 복제 전 Primary 장애 → 데이터 영구 손실

### 3. 최종 일관성 (Eventual Consistency)

**정의:**
쓰기가 더 이상 발생하지 않으면, 충분한 시간이 지난 후 모든 노드가 동일한 값으로 수렴.

```
시간 ──────────────────────────────────────▶

노드1: Write(x=10) ───────────────────┐
                                      │
노드2: Read(x) → 5 (구값) ───┐        │
                             │ 복제   │
노드3: Read(x) → 5 (구값)    │        │
                             ▼        ▼
                         복제 완료  최종 일관
노드2: Read(x) → 10 ✓
노드3: Read(x) → 10 ✓

일시적 불일치 → 최종적으로 수렴
```

**구현 방법:**

**(1) 비동기 레플리케이션 (Asynchronous Replication)**

```
┌──────────────────────────────────────────────────────────┐
│                   비동기 쓰기 과정                        │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  Client                                                  │
│    │                                                     │
│    │ Write(x=10)                                        │
│    ▼                                                     │
│  ┌────────┐                                             │
│  │ Master │                                             │
│  └────┬───┘                                             │
│       │                                                  │
│       │ Success (즉시 응답)                             │
│       ▼                                                  │
│    Client ← 빠른 응답                                   │
│                                                          │
│  ┌────────┐  백그라운드 복제                            │
│  │ Master │ ──────────────┐                             │
│  └────────┘               │                             │
│                           ▼                             │
│                      ┌────────┐                         │
│                      │Replica1│ (수 ms~초 후 반영)      │
│                      └────────┘                         │
│                           │                             │
│                           ▼                             │
│                      ┌────────┐                         │
│                      │Replica2│ (수 ms~초 후 반영)      │
│                      └────────┘                         │
│                                                          │
└──────────────────────────────────────────────────────────┘

쓰기 지연: Master 지연만 (10ms)
복제 지연: 수 ms ~ 수 초 (네트워크 상황에 따라)
```

**(2) 충돌 해결 (Conflict Resolution)**

```
충돌 발생 상황:
┌────────────────────────────────────────────────────────┐
│ 시간: T1                                               │
│ 노드A: Write(name="Alice")                             │
│ 노드B: Write(name="Bob")                               │
│                                                        │
│ → 두 쓰기가 동시에 다른 노드에서 발생                   │
│ → 복제 후 충돌!                                        │
└────────────────────────────────────────────────────────┘

충돌 해결 전략:

[1] Last Write Wins (LWW) - 타임스탬프 기준
├── 각 쓰기에 타임스탬프 부여
├── T1=10:00:00 (Alice), T1=10:00:01 (Bob)
└── → "Bob" 선택 (더 최근)

문제점: 시계 동기화 필요, 의미있는 데이터 손실 가능

[2] Version Vector - 버전 추적
├── 각 노드가 버전 벡터 유지
├── 충돌 시 애플리케이션에게 전달
└── → 사용자가 선택 또는 병합

예: Amazon Shopping Cart (모든 추가 항목 유지)

[3] CRDT (Conflict-free Replicated Data Type)
├── 교환/결합/멱등 법칙을 만족하는 자료구조
├── 연산 순서 무관하게 수렴
└── → 자동 병합

예: Counter, Set, Map
```

**CRDT 예시:**

```java
// G-Counter (Grow-only Counter) - CRDT 구현
public class GCounter {
    // 각 노드별 카운터 유지
    private Map<String, Long> counters = new HashMap<>();
    private String nodeId;

    public void increment() {
        counters.merge(nodeId, 1L, Long::sum);
    }

    // 다른 노드의 상태 병합
    public void merge(GCounter other) {
        for (Map.Entry<String, Long> entry : other.counters.entrySet()) {
            String node = entry.getKey();
            Long value = entry.getValue();
            // 각 노드별로 최댓값 선택
            counters.merge(node, value, Math::max);
        }
    }

    // 전체 합계
    public long value() {
        return counters.values().stream()
                       .mapToLong(Long::longValue)
                       .sum();
    }
}

// 사용 예:
// 노드A: increment() → {A: 1}
// 노드B: increment() → {B: 1}
// 병합 후: {A: 1, B: 1} → value() = 2
// 연산 순서 무관하게 항상 동일한 결과
```

**왜 이렇게 하는가?**
- 성능 향상: 네트워크 지연 대기 없이 즉시 응답
- 가용성 향상: 일부 노드 장애 시에도 쓰기 가능
- 확장성: 읽기를 여러 노드에 분산 가능

**만약 지키지 않으면?**
- 강한 일관성만 사용: 모든 쓰기가 느려지고, 네트워크 분할 시 쓰기 불가
- 충돌 해결 전략 없음: 동시 쓰기 시 데이터 손실 또는 임의 값 선택

### 4. 분산 시스템에서의 일관성

**분산 시스템의 도전 과제:**

```
┌─────────────────────────────────────────────────────────┐
│              분산 시스템의 3가지 어려움                  │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  [1] 네트워크 지연 (Network Latency)                    │
│      ┌──────┐  100ms  ┌──────┐                         │
│      │ 서울 │ ◀─────▶ │ 미국 │                         │
│      └──────┘         └──────┘                         │
│      → 물리적 거리로 인한 필연적 지연                    │
│                                                         │
│  [2] 네트워크 분할 (Network Partition)                  │
│      ┌──────┐    X    ┌──────┐                         │
│      │노드 A│ ◀─────▶ │노드 B│                         │
│      └──────┘  단절   └──────┘                         │
│      → 라우터 장애, 케이블 절단 등                       │
│                                                         │
│  [3] 노드 장애 (Node Failure)                           │
│      ┌──────┐         ┌──────┐                         │
│      │노드 A│         │노드 B│                         │
│      └──────┘         └──💀───┘                         │
│      → 서버 다운, 프로세스 크래시 등                     │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

**읽기 후 쓰기 일관성 (Read-after-Write Consistency):**

```
문제 상황:
사용자: 프로필 사진 업로드 (Master에 쓰기)
       → 즉시 새로고침 (Replica에서 읽기)
       → 아직 이전 사진 보임 ❌

해결:
사용자가 수정한 데이터는 항상 Master에서 읽기
       → 업데이트 직후에도 최신 데이터 보임 ✓

구현:
if (사용자가 최근 1분 내 수정) {
    Master에서 읽기
} else {
    Replica에서 읽기 (부하 분산)
}
```

**단조 읽기 (Monotonic Reads):**

```
문제 상황:
시간 T1: Replica1에서 읽기 → version 10
시간 T2: Replica2에서 읽기 → version 5 (지연된 복제)
       → 시간이 거꾸로 간 것처럼 보임 ❌

해결:
같은 사용자는 항상 같은 Replica에서 읽기
       → 버전이 뒤로 가지 않음 ✓

구현:
replicaId = hash(userId) % replicaCount
해당 replicaId의 Replica에서만 읽기
```

**일관된 접두사 읽기 (Consistent Prefix Reads):**

```
문제 상황 (인과 관계 위반):
노드A: "안녕하세요" (질문)
노드B: "네, 반갑습니다" (답변)

읽기 시:
Replica1: "네, 반갑습니다" ← 답변만 먼저 복제됨
Replica2: (질문 아직 도착 안 함)
       → 대화 순서가 뒤바뀜 ❌

해결:
인과 관계 있는 데이터는 순서 보장
       → 질문이 먼저 보이고 답변이 나중에 보임 ✓

구현:
벡터 시계(Vector Clock) 또는 인과 관계 추적
```

### 5. CAP 정리와 일관성

**CAP 정리 (Brewer's Theorem):**

```
        Consistency (일관성)
             ▲
            /│\
           / │ \
          /  │  \
         /   │   \
        / CP │ CA \
       /     │     \
      /      │      \
     /       │       \
    /        │        \
   ▼─────────┴─────────▼
Partition              Availability
Tolerance                (가용성)
(분할 내성)
    AP

┌──────────────────────────────────────────────────────────┐
│ 분산 시스템에서 네트워크 분할(P)은 피할 수 없다           │
│ → 실질적으로 CP vs AP 선택                               │
└──────────────────────────────────────────────────────────┘
```

**CP vs AP 선택:**

| 선택 | 특징 | 예시 시스템 | 사용 사례 |
|------|------|-----------|----------|
| **CP** | 일관성 우선, 가용성 희생 | HBase, MongoDB (기본), Redis (Sentinel) | 금융 거래, 재고 관리, 분산 락 |
| **AP** | 가용성 우선, 일관성 희생 | Cassandra, DynamoDB, Riak | SNS 타임라인, 로그 수집, 세션 저장 |

**네트워크 분할 시 동작:**

```
[네트워크 분할 발생]
┌──────────────┐        ╳        ┌──────────────┐
│   Partition1 │     단절됨      │   Partition2 │
│  (노드 A, B) │                 │  (노드 C, D) │
└──────────────┘                 └──────────────┘


[CP 시스템 - 일관성 우선]
┌──────────────┐                 ┌──────────────┐
│ Partition1   │                 │ Partition2   │
│ (과반수 O)   │                 │ (과반수 X)   │
│ 쓰기/읽기 OK │                 │ 503 Error    │
└──────────────┘                 └──────────────┘
                                 (가용성 희생)

→ 일관성 유지하지만 일부 노드 사용 불가


[AP 시스템 - 가용성 우선]
┌──────────────┐                 ┌──────────────┐
│ Partition1   │                 │ Partition2   │
│ 쓰기/읽기 OK │                 │ 쓰기/읽기 OK │
└──────────────┘                 └──────────────┘
  (다른 값)                       (다른 값)

→ 모두 사용 가능하지만 일시적 불일치
→ 분할 해소 후 충돌 해결 필요
```

**실무에서의 선택:**

```java
// 기능별로 다르게 선택하는 예시
public class HybridConsistencyService {

    // 강한 일관성 (CP) - 결제
    @Transactional
    public void processPayment(Payment payment) {
        // 모든 노드에 동기 복제
        masterDB.save(payment);
        waitForReplication(); // 복제 대기
        // 일관성 보장되면 성공
    }

    // 최종 일관성 (AP) - 좋아요
    public void addLike(Long postId, Long userId) {
        // 로컬 노드에만 즉시 저장
        localDB.save(new Like(postId, userId));
        // 비동기 복제 (백그라운드)
        replicateAsync(postId, userId);
        // 즉시 성공 응답
    }

    // 세션 일관성 - 장바구니
    public Cart getCart(Long userId) {
        // 같은 사용자는 항상 같은 샤드
        int shardId = hash(userId) % shardCount;
        return shards.get(shardId).getCart(userId);
    }
}
```

**왜 이렇게 하는가?**
- CAP는 트레이드오프: 모두 만족 불가능 (물리적 한계)
- 기능별 선택: 결제는 CP, SNS는 AP (비즈니스 요구사항에 따라)
- 하이브리드: 하나의 시스템에서 기능별로 다른 일관성 수준 적용 가능

**만약 지키지 않으면?**
- 모든 기능을 CP로: SNS 좋아요도 동기 복제 → 성능 저하, 가용성 감소
- 모든 기능을 AP로: 결제도 비동기 복제 → 중복 결제, 데이터 손실
- CAP 이해 없이 설계: 네트워크 분할 시 예상치 못한 동작

## 트레이드오프

| 강한 일관성 (CP) | vs | 최종 일관성 (AP) |
|-----------------|----|--------------------|
| 데이터 정합성 보장 | ↔ | 일시적 불일치 허용 |
| 쓰기 성능 낮음 (동기 복제) | ↔ | 쓰기 성능 높음 (비동기) |
| 가용성 낮음 (분할 시 차단) | ↔ | 가용성 높음 (항상 응답) |
| 구현 단순 (중앙 조정) | ↔ | 구현 복잡 (충돌 해결) |
| 확장성 낮음 | ↔ | 확장성 높음 |

**일관성 vs 지연시간:**

```
      지연시간
       ▲
  300ms│                      최종 일관성
       │                   (비동기 복제)
  200ms│
       │
  100ms│              세션 일관성
       │
   50ms│        인과적 일관성
       │
   10ms│  강한 일관성
       │ (동기 복제)
       └───────────────────────────────▶ 일관성 수준
```

**일관성 vs 가용성:**

```
네트워크 분할 상황에서:

강한 일관성 (CP):
├── 장점: 데이터 정합성 유지
└── 단점: 과반수 미달 파티션은 응답 불가 (가용성 ↓)

최종 일관성 (AP):
├── 장점: 모든 파티션이 응답 (가용성 ↑)
└── 단점: 충돌 발생 가능, 해결 복잡도 ↑
```

## 면접 예상 질문

- Q: 강한 일관성과 최종 일관성의 차이는 무엇인가요?
  - A: 강한 일관성은 쓰기 후 즉시 모든 노드에서 최신 데이터를 읽을 수 있지만, 최종 일관성은 일정 시간이 지나야 모든 노드가 일관된 상태에 도달합니다. **왜 이런 차이가 발생하는가?** 강한 일관성은 모든 노드에 동기식으로 복제하고 ACK를 받아야 하므로 네트워크 지연만큼 느리지만, 최종 일관성은 비동기로 복제하므로 빠르게 응답할 수 있습니다. **트레이드오프:** 강한 일관성은 정합성이 중요한 금융/재고에, 최종 일관성은 성능/가용성이 중요한 SNS/로그에 적합합니다.

- Q: CAP 정리를 설명하고, 실무에서 어떻게 선택하나요?
  - A: CAP 정리는 분산 시스템에서 일관성(C), 가용성(A), 분할 내성(P) 중 2개만 만족할 수 있다는 이론입니다. **왜 2개만 가능한가?** 네트워크 분할(P)은 피할 수 없으므로, 실질적으로 CP(일관성 우선) vs AP(가용성 우선) 선택입니다. **CP 선택:** 분할 시 과반수 없는 파티션은 응답 거부 (예: 금융, HBase). **AP 선택:** 분할 시에도 모든 노드 응답, 나중에 충돌 해결 (예: SNS, Cassandra). **실무 팁:** 한 시스템에서도 기능별로 다르게 선택 가능합니다 (결제는 CP, 좋아요는 AP).

- Q: 최종 일관성에서 충돌은 어떻게 해결하나요?
  - A: 대표적인 충돌 해결 전략은 3가지입니다. **(1) Last Write Wins (LWW)**: 타임스탬프가 늦은 쓰기를 선택. 단순하지만 의미있는 데이터가 손실될 수 있습니다. **(2) Version Vector**: 각 쓰기의 버전을 추적하고 충돌 시 애플리케이션에 전달하여 사용자가 선택. Amazon Shopping Cart가 이 방식으로 모든 추가 항목을 유지합니다. **(3) CRDT**: 교환/결합 법칙을 만족하는 자료구조로 연산 순서 무관하게 자동 병합. 예: G-Counter (각 노드별 카운터 유지 후 합산). **왜 CRDT가 좋은가?** 애플리케이션 로직 수정 없이 자동으로 수렴하기 때문입니다.

- Q: 읽기 후 쓰기 일관성(Read-after-Write Consistency)이란?
  - A: 사용자가 쓴 데이터는 즉시 자신의 읽기에 반영되는 것을 보장하는 일관성 모델입니다. **왜 필요한가?** 프로필 사진을 업데이트 후 새로고침 시 이전 사진이 보이면 사용자가 혼란스럽기 때문입니다. **구현 방법:** 사용자가 최근 수정한 데이터는 Master에서 읽고, 그 외에는 Replica에서 읽어 부하 분산합니다. **예:** `if (최근 1분 내 수정) { Master 읽기 } else { Replica 읽기 }`. 이를 통해 사용자 경험을 개선하면서도 읽기 부하를 분산할 수 있습니다.

- Q: 금융 시스템에서 강한 일관성을 어떻게 구현하나요?
  - A: 분산 합의 알고리즘(Raft, Paxos)과 2단계 커밋(2PC)을 사용합니다. **Raft 예시:** (1) 리더가 쓰기 로그를 과반수 노드에 복제, (2) 과반수 ACK 받으면 커밋, (3) 클라이언트에 성공 응답. **왜 과반수인가?** 네트워크 분할 시 과반수를 가진 파티션만 쓰기를 허용하여 Split-Brain을 방지합니다. **2PC:** 트랜잭션 코디네이터가 (1) Prepare 단계에서 모든 참여자에게 준비 요청, (2) 모두 OK면 Commit, 하나라도 실패면 Rollback. **트레이드오프:** 강한 일관성 보장하지만 코디네이터가 단일 장애점이 되고 성능이 저하됩니다.

## 연관 문서

| 문서 | 연관성 | 난이도 |
|------|--------|--------|
| [가용성](./availability.md) | CAP 정리: 일관성 vs 가용성 트레이드오프 | 입문 |
| [캐싱](./caching.md) | 캐시와 DB 간 일관성 문제 | 중급 |
| [대규모 시스템 설계](./large-scale-system.md) | 일관성을 고려한 전체 시스템 설계 | 심화 |
| [메시지 큐](./message-queue.md) | 비동기 통신과 최종 일관성 | 중급 |

## 참고 자료

- Martin Kleppmann, "Designing Data-Intensive Applications" - Chapter 5 (Replication), Chapter 9 (Consistency and Consensus)
- [Brewer's CAP Theorem](https://users.ece.cmu.edu/~adrian/731-sp04/readings/GL-cap.pdf)
- [Amazon DynamoDB - Eventual Consistency](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html)
- [Google Spanner - External Consistency](https://cloud.google.com/spanner/docs/true-time-external-consistency)
- [CRDT (Conflict-free Replicated Data Types)](https://crdt.tech/)
